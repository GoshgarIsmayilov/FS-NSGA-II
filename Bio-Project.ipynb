{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature (Gene) Selection for Microarray Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get user inputs (name of dataset and objectives be considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = sys.argv[1]\n",
    "objectives   = sys.argv[2]\n",
    "dataset_name = 'shipp'     # gordon: lung # shipp: lymphoma # singh: prostate # tian: myeloma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('Datasets/' + dataset_name + '_inputs.csv', header = None)\n",
    "labels = pd.read_csv('Datasets/' + dataset_name + '_outputs.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-process dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.fillna(0, inplace = True)\n",
    "samples = np.asarray(samples.values)\n",
    "labels = np.transpose(np.asarray(labels.values.ravel() - 1, dtype=int))\n",
    "samples = preprocessing.MinMaxScaler().fit_transform(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pre-select best 100 features with univariate chi square statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = SelectKBest(chi2, k = 100).fit_transform(samples, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Be ready! Last preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes           = [0, 1]\n",
    "scores            = []\n",
    "loo               = LeaveOneOut()\n",
    "cv                = KFold(n_splits = 10, shuffle=False)\n",
    "number_of_classes = np.max(labels) + 1\n",
    "batch_size        = 1\n",
    "epochs            = 5\n",
    "\n",
    "acc_scores        = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.03802657127380371\n",
      "Score: 0.7892857142857143\n"
     ]
    }
   ],
   "source": [
    "def linearSVM(indexes,print_time=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = LinearSVC(random_state=0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = linearSVM(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Apply Non-Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.3252584934234619\n",
      "Score: 0.849343185550082\n"
     ]
    }
   ],
   "source": [
    "def nonLinearSVM(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = SVC(kernel = 'rbf', random_state=0) # rbf == gaussian\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = nonLinearSVM(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Apply k-NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.35024237632751465\n",
      "Score: 0.8286149825783972\n"
     ]
    }
   ],
   "source": [
    "def kNN(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = kNN(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Apply MLP classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 95.73374009132385\n",
      "Score: 0.833580320094843\n"
     ]
    }
   ],
   "source": [
    "def MLP(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu', solver='adam', max_iter=3000)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = MLP(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply decision tree classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.2291550636291504\n",
      "Score: 0.8141284815813117\n"
     ]
    }
   ],
   "source": [
    "def DTree(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        decision_tree = DecisionTreeClassifier()\n",
    "        decision_tree = decision_tree.fit(X_train, Y_train)\n",
    "        score = decision_tree.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = DTree(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random forest classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 42.683528423309326\n",
      "Score: 0.8098553345388788\n"
     ]
    }
   ],
   "source": [
    "def RForest(indexes, print_time=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=100)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = RForest(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a classifier with maximum accuracy score to be used in multi-objective algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_selection(scores):\n",
    "    return acc_scores.index(max(scores))\n",
    "\n",
    "def selected_function(indexes, selection):\n",
    "    \n",
    "    if selection == 0:\n",
    "        score = linearSVM(indexes, False)\n",
    "    elif selection == 1:\n",
    "        score = nonLinearSVM(indexes, False)\n",
    "    elif selection == 2:\n",
    "        score = kNN(indexes, False)\n",
    "    elif selection == 3:\n",
    "        score = MLP(indexes, False)\n",
    "    elif selection == 4:\n",
    "        score = DTree(indexes, False)\n",
    "    elif selection == 5:\n",
    "        score = RForest(indexes, False)\n",
    "        \n",
    "    return score\n",
    "\n",
    "selected_classifier = classifier_selection(acc_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Apply NSGA-II!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best front for Generation number  0  is\n",
      "[1, 0, 1, 0, 1, 1, 0, 0, 0, 0] 0.8443801476853167 [1, 0, 0, 0, 0, 0, 1, 0, 1, 0] 0.844371879915202 \n",
      "\n",
      "The best front for Generation number  1  is\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 1, 0] 0.849969474969475 [1, 0, 0, 0, 1, 0, 1, 1, 0, 0] 0.8501956662017859 [1, 1, 0, 0, 0, 1, 0, 1, 0, 1] 0.8504168382050226 \n",
      "\n",
      "The best front for Generation number  2  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 1] 0.856397083195227 [1, 0, 1, 0, 1, 0, 0, 0, 0, 1] 0.8566580892216883 [1, 1, 1, 1, 1, 1, 1, 0, 0, 1] 0.8567460654009716 \n",
      "\n",
      "The best front for Generation number  3  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 1, 0] 0.8567378006515561 [1, 0, 1, 0, 1, 0, 0, 0, 0, 1] 0.856920788236816 \n",
      "\n",
      "The best front for Generation number  4  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.8577693940900599 [0, 0, 0, 1, 0, 0, 0, 1, 1, 0] 0.8576734081795236 [1, 1, 0, 0, 1, 0, 0, 0, 0, 1] 0.8578115827952397 \n",
      "\n",
      "The best front for Generation number  5  is\n",
      "[1, 0, 1, 0, 0, 1, 0, 1, 0, 0] 0.8560829034252233 [1, 0, 0, 0, 0, 0, 0, 0, 1, 0] 0.8560096547209949 \n",
      "\n",
      "The best front for Generation number  6  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.856667622531902 [1, 0, 1, 0, 0, 0, 0, 0, 0, 1] 0.8566688043257608 \n",
      "\n",
      "The best front for Generation number  7  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.8548524398402416 [1, 0, 0, 1, 0, 1, 0, 0, 0, 1] 0.8548853561235339 \n",
      "\n",
      "The best front for Generation number  8  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.8562852196647176 [1, 0, 0, 1, 0, 0, 0, 1, 0, 1] 0.8563115337959828 \n",
      "\n",
      "The best front for Generation number  9  is\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 1] 0.8561324704625817 [1, 0, 0, 1, 0, 1, 0, 1, 0, 0] 0.8561341884278332 \n",
      "\n",
      "The best front for Generation number  10  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1] 0.8567291450521748 \n",
      "\n",
      "The best front for Generation number  11  is\n",
      "[1, 1, 0, 0, 0, 0, 0, 1, 0, 0] 0.8567646828299718 \n",
      "\n",
      "The best front for Generation number  12  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0] 0.8567103905071468 [1, 0, 1, 1, 0, 0, 0, 0, 0, 0] 0.8567109506028671 \n",
      "\n",
      "The best front for Generation number  13  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0] 0.8542172819931545 [1, 0, 1, 1, 0, 0, 0, 0, 1, 0] 0.8542519283979394 \n",
      "\n",
      "The best front for Generation number  14  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1] 0.8555080574123011 [1, 1, 0, 1, 0, 1, 0, 0, 0, 0] 0.855524374034707 \n",
      "\n",
      "The best front for Generation number  15  is\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0.8556275235368574 [1, 0, 1, 1, 0, 0, 0, 0, 0, 1] 0.855629105090312 \n",
      "\n",
      "The best front for Generation number  16  is\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0.8565352778298632 [1, 0, 1, 1, 0, 0, 0, 0, 1, 0] 0.8565613349095208 \n",
      "\n",
      "The best front for Generation number  17  is\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0] 0.8569785440573577 \n",
      "\n",
      "The best front for Generation number  18  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 0, 1] 0.8575331217268132 [1, 1, 0, 0, 0, 1, 0, 0, 0, 0] 0.8575327803267726 \n",
      "\n",
      "The best front for Generation number  19  is\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0] 0.8578797305500858 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#First function to optimize\n",
    "def function1(x):\n",
    "    value = -sum(x)\n",
    "    return value\n",
    "\n",
    "#Second function to optimize\n",
    "def function2(x):\n",
    "    indexes = [i for i, v in enumerate(x) if v == 1]\n",
    "    if indexes == []: indexes = [0]\n",
    "    value = selected_function(indexes, selected_classifier)\n",
    "    return value\n",
    "\n",
    "#Function to find index of list\n",
    "def index_of(a,list):\n",
    "    for i in range(0,len(list)):\n",
    "        if list[i] == a:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "#Function to sort by values\n",
    "def sort_by_values(list1, values):\n",
    "    sorted_list = []\n",
    "    while(len(sorted_list)!=len(list1)):\n",
    "        if index_of(min(values),values) in list1:\n",
    "            sorted_list.append(index_of(min(values),values))\n",
    "        values[index_of(min(values),values)] = math.inf\n",
    "    return sorted_list\n",
    "\n",
    "#Function to carry out NSGA-II's fast non dominated sort\n",
    "def fast_non_dominated_sort(values1, values2):\n",
    "    S=[[] for i in range(0,len(values1))]\n",
    "    front = [[]]\n",
    "    n=[0 for i in range(0,len(values1))]\n",
    "    rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "    for p in range(0,len(values1)):\n",
    "        S[p]=[]\n",
    "        n[p]=0\n",
    "        for q in range(0, len(values1)):\n",
    "            if (values1[p] > values1[q] and values2[p] > values2[q]) or (values1[p] >= values1[q] and values2[p] > values2[q]) or (values1[p] > values1[q] and values2[p] >= values2[q]):\n",
    "                if q not in S[p]:\n",
    "                    S[p].append(q)\n",
    "            elif (values1[q] > values1[p] and values2[q] > values2[p]) or (values1[q] >= values1[p] and values2[q] > values2[p]) or (values1[q] > values1[p] and values2[q] >= values2[p]):\n",
    "                n[p] = n[p] + 1\n",
    "        if n[p]==0:\n",
    "            rank[p] = 0\n",
    "            if p not in front[0]:\n",
    "                front[0].append(p)\n",
    "\n",
    "    i = 0\n",
    "    while(front[i] != []):\n",
    "        Q=[]\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] =n[q] - 1\n",
    "                if( n[q]==0):\n",
    "                    rank[q]=i+1\n",
    "                    if q not in Q:\n",
    "                        Q.append(q)\n",
    "        i = i+1\n",
    "        front.append(Q)\n",
    "\n",
    "    del front[len(front)-1]\n",
    "    return front\n",
    "\n",
    "#Function to calculate crowding distance\n",
    "def crowding_distance(values1, values2, front):\n",
    "    distance = [0 for i in range(0,len(front))]\n",
    "    sorted1 = sort_by_values(front, values1[:])\n",
    "    sorted2 = sort_by_values(front, values2[:])\n",
    "    distance[0] = 4444444444444444\n",
    "    distance[len(front) - 1] = 4444444444444444\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "    return distance\n",
    "\n",
    "#Function to carry out the crossover\n",
    "def crossover(solution1, solution2):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    tmp = solution1[:r].copy()\n",
    "    solution1[:r], solution2[:r]  = solution2[:r], tmp\n",
    "    return solution1\n",
    "\n",
    "#Function to carry out the mutation operator\n",
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "#Main program starts here\n",
    "pop_size = 20\n",
    "max_gen = 20\n",
    "number_of_genes = 10\n",
    "\n",
    "#Initialization\n",
    "solution = [list(np.random.randint(2, size = number_of_genes)) for i in range(0,pop_size)]\n",
    "[mutation(s) for s in solution if sum(s) == 0]\n",
    "gen_no = 0\n",
    "while(gen_no<max_gen):\n",
    "    function1_values = [function1(solution[i]) for i in range(0,pop_size)]\n",
    "    function2_values = [function2(solution[i]) for i in range(0,pop_size)]\n",
    "    non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])\n",
    "    print(\"The best front for Generation number \",gen_no, \" is\")\n",
    "    for valuez in non_dominated_sorted_solution[0]:\n",
    "        print(solution[valuez], function2(solution[valuez]), end=\" \")\n",
    "    print(\"\\n\")\n",
    "    crowding_distance_values=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution)):\n",
    "        crowding_distance_values.append(crowding_distance(function1_values[:],function2_values[:],non_dominated_sorted_solution[i][:]))\n",
    "    solution2 = solution[:]\n",
    "    #Generating offsprings\n",
    "    while(len(solution2)!=2*pop_size):\n",
    "        a1 = random.randint(0,pop_size-1)\n",
    "        b1 = random.randint(0,pop_size-1)\n",
    "        c1 = crossover(solution[a1],solution[b1])\n",
    "        #d1 = mutation(c1)\n",
    "        solution2.append(c1)\n",
    "    [mutation(s) for s in solution2 if sum(s) == 0]\n",
    "    function1_values2 = [function1(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    function2_values2 = [function2(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    non_dominated_sorted_solution2 = fast_non_dominated_sort(function1_values2[:],function2_values2[:])\n",
    "    crowding_distance_values2=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        crowding_distance_values2.append(crowding_distance(function1_values2[:],function2_values2[:],non_dominated_sorted_solution2[i][:]))\n",
    "    new_solution= []\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i]) for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "        front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front.reverse()\n",
    "        for value in front:\n",
    "            new_solution.append(value)\n",
    "            if(len(new_solution)==pop_size):\n",
    "                break\n",
    "        if (len(new_solution) == pop_size):\n",
    "            break\n",
    "    solution = [solution2[i] for i in new_solution]\n",
    "    gen_no = gen_no + 1\n",
    "\n",
    "#Lets plot the final front now\n",
    "function1 = [i * -1 for i in function1_values]\n",
    "function2 = [j * -1 for j in function2_values]\n",
    "plt.xlabel('Function 1', fontsize=15)\n",
    "plt.ylabel('Function 2', fontsize=15)\n",
    "plt.scatter(function1, function2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "solution = [list(np.random.randint(2, size = 10)) for i in range(0,10)]\n",
    "print(solution)\n",
    "print()\n",
    "[mutation(s) for s in solution if sum(s) == 5]\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "Author:\n",
    "    GOSHGAR ISMAYILOV\n",
    "    SERHAT İŞCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
