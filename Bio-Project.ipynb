{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature (Gene) Selection for Microarray Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get user inputs (name of dataset and objectives be considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = sys.argv[1]\n",
    "dataset_name = 'shipp'          # gordon: lung # shipp: lymphoma # singh: prostate # tian: myeloma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('Datasets/' + dataset_name + '_inputs.csv', header = None)\n",
    "labels = pd.read_csv('Datasets/' + dataset_name + '_outputs.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-process dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.fillna(0, inplace = True)\n",
    "samples = np.asarray(samples.values)\n",
    "labels = np.transpose(np.asarray(labels.values.ravel() - 1, dtype=int))\n",
    "samples = preprocessing.MinMaxScaler().fit_transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pre-select best 100 features with univariate chi square statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_features_preselected = 50\n",
    "samples = SelectKBest(chi2, k = number_of_features_preselected).fit_transform(samples, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Be ready! Last preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes           = list(range(0, number_of_features_preselected))       # [0, 1]\n",
    "scores            = []\n",
    "cv                = KFold(n_splits = 10, shuffle=False)\n",
    "number_of_classes = np.max(labels) + 1\n",
    "batch_size        = 1\n",
    "epochs            = 5\n",
    "acc_scores        = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.009966850280761719\n",
      "Score: 0.9482142857142858\n"
     ]
    }
   ],
   "source": [
    "def linearSVM(indexes,print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = LinearSVC(random_state=0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = linearSVM(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Apply Non-Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.01000213623046875\n",
      "Score: 0.9339285714285716\n"
     ]
    }
   ],
   "source": [
    "def nonLinearSVM(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = SVC(kernel = 'rbf', random_state=0) # rbf == gaussian\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = nonLinearSVM(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Apply k-NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.01800084114074707\n",
      "Score: 0.9160714285714288\n"
     ]
    }
   ],
   "source": [
    "def kNN(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = kNN(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Apply MLP classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3.7245516777038574\n",
      "Score: 0.9107142857142858\n"
     ]
    }
   ],
   "source": [
    "def MLP(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu', solver='adam', max_iter=3000)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = MLP(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply decision tree classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.013001203536987305\n",
      "Score: 0.8878571428571428\n"
     ]
    }
   ],
   "source": [
    "def DTree(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        decision_tree = DecisionTreeClassifier()\n",
    "        decision_tree = decision_tree.fit(X_train, Y_train)\n",
    "        score = decision_tree.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = DTree(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random forest classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.7467172145843506\n",
      "Score: 0.8883928571428571\n"
     ]
    }
   ],
   "source": [
    "def RForest(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=100)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = RForest(indexes)\n",
    "acc_scores.append(score)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting a classifier with maximum accuracy score to be used in multi-objective algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "def classifier_selection(scores):\n",
    "    return acc_scores.index(max(scores))\n",
    "\n",
    "def selected_function(indexes, selection):  \n",
    "    if selection == 0:\n",
    "        score = linearSVM(indexes, False)\n",
    "    elif selection == 1:\n",
    "        score = nonLinearSVM(indexes, False)\n",
    "    elif selection == 2:\n",
    "        score = kNN(indexes, False)\n",
    "    elif selection == 3:\n",
    "        score = MLP(indexes, False)\n",
    "    elif selection == 4:\n",
    "        score = DTree(indexes, False)\n",
    "    elif selection == 5:\n",
    "        score = RForest(indexes, False)        \n",
    "    return score\n",
    "\n",
    "selected_classifier = classifier_selection(acc_scores)\n",
    "print(selected_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Apply NSGA-II!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best front for Generation number  0  is\n",
      "[0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] -15 0.9249518815994298 \n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1] -20 0.9249512384953325 \n",
      "\n",
      "[0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0] -21 0.9249524122087299 \n",
      "\n",
      "[0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1] -23 0.924952648185394 \n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0] -25 0.9249534115628399 \n",
      "\n",
      "[0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1] -24 0.9249532958919137 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  1  is\n",
      "[0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] -17 0.9250081635318704 \n",
      "\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0] -19 0.9250089212827989 \n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0] -20 0.9250087460700992 \n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1] -22 0.9250095037525246 \n",
      "\n",
      "[0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0] -23 0.9250097949588612 \n",
      "\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0] -25 0.9250109606675281 \n",
      "\n",
      "[0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0] -26 0.9250121263000792 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  2  is\n",
      "[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0] -16 0.9250609142003183 \n",
      "\n",
      "[0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0] -18 0.9250616663727411 \n",
      "\n",
      "[0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0] -22 0.9250628245645787 \n",
      "\n",
      "[0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1] -25 0.9250631125631126 \n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0] -31 0.9250638645908257 \n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0] -29 0.925063746508153 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  3  is\n",
      "[0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0] -16 0.9251255431545213 \n",
      "\n",
      "[0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0] -19 0.9251266934791241 \n",
      "\n",
      "[0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1] -22 0.9251274397085509 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  4  is\n",
      "[0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1] -17 0.9251725405504755 \n",
      "\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] -18 0.9251736837026793 \n",
      "\n",
      "[0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0] -25 0.9251744247486722 \n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0] -24 0.9251743042761117 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  5  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1] -19 0.9252345021672732 \n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0] -21 0.9252347804220102 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  6  is\n",
      "[0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0] -25 0.9253123123054803 \n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1] -17 0.9253121886076467 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  7  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1] -15 0.9254092969443388 \n",
      "\n",
      "[0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0] -18 0.9254104159968846 \n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0] -19 0.9254111387819787 \n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0] -22 0.9254118049235478 \n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1] -27 0.925412527618806 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  8  is\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] -15 0.9254913910806096 \n",
      "\n",
      "[0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0] -21 0.9254925020727442 \n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1] -24 0.9254932187352153 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  9  is\n",
      "[0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0] -16 0.9255171149637654 \n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0] -20 0.9255169866232583 \n",
      "\n",
      "[1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1] -23 0.9255176990753612 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  10  is\n",
      "[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0] -14 0.9255438202648362 \n",
      "\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0] -19 0.9255444727094211 \n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] -18 0.9255438978565405 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best front for Generation number  11  is\n",
      "[0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0] -17 0.9256014751214832 \n",
      "\n",
      "[0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0] -18 0.9256013453791179 \n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0] -19 0.9256020484303658 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  12  is\n",
      "[0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0] -18 0.9256618443447315 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  13  is\n",
      "[1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0] -18 0.9257296644401615 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  14  is\n",
      "[0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0] -17 0.9258288294009697 \n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0] -20 0.925829132468488 \n",
      "\n",
      "[0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1] -21 0.9258297639850568 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  15  is\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0] -19 0.9259088234011944 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  16  is\n",
      "[1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0] -18 0.9258961930508968 \n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1] -20 0.9258968709590634 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  17  is\n",
      "[0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1] -19 0.925924578097801 \n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1] -17 0.9259227144325711 \n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0] -21 0.9259230104740309 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  18  is\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0] -15 0.9259841152797723 \n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0] -18 0.9259847843191209 \n",
      "\n",
      "[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1] -22 0.9259850233881924 \n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1] -25 0.9259856923599439 \n",
      "\n",
      "\n",
      "\n",
      "The best front for Generation number  19  is\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1] -19 0.9259920932123599 \n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0] -21 0.9259927589261641 \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#First function to optimize\n",
    "def function1(x):\n",
    "    value = -sum(x)\n",
    "    return value\n",
    "\n",
    "#Second function to optimize\n",
    "def function2(x):\n",
    "    indexes = [i for i, v in enumerate(x) if v == 1]\n",
    "    if indexes == []: indexes = [0]\n",
    "    value = selected_function(indexes, selected_classifier)\n",
    "    return value\n",
    "\n",
    "#Function to find index of list\n",
    "def index_of(a,list):\n",
    "    for i in range(0,len(list)):\n",
    "        if list[i] == a:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "#Function to sort by values\n",
    "def sort_by_values(list1, values):\n",
    "    sorted_list = []\n",
    "    while(len(sorted_list)!=len(list1)):\n",
    "        if index_of(min(values),values) in list1:\n",
    "            sorted_list.append(index_of(min(values),values))\n",
    "        values[index_of(min(values),values)] = math.inf\n",
    "    return sorted_list\n",
    "\n",
    "#Function to carry out NSGA-II's fast non dominated sort\n",
    "def fast_non_dominated_sort(values1, values2):\n",
    "    S=[[] for i in range(0,len(values1))]\n",
    "    front = [[]]\n",
    "    n=[0 for i in range(0,len(values1))]\n",
    "    rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "    for p in range(0,len(values1)):\n",
    "        S[p]=[]\n",
    "        n[p]=0\n",
    "        for q in range(0, len(values1)):\n",
    "            if (values1[p] > values1[q] and values2[p] > values2[q]) or (values1[p] >= values1[q] and values2[p] > values2[q]) or (values1[p] > values1[q] and values2[p] >= values2[q]):\n",
    "                if q not in S[p]:\n",
    "                    S[p].append(q)\n",
    "            elif (values1[q] > values1[p] and values2[q] > values2[p]) or (values1[q] >= values1[p] and values2[q] > values2[p]) or (values1[q] > values1[p] and values2[q] >= values2[p]):\n",
    "                n[p] = n[p] + 1\n",
    "        if n[p]==0:\n",
    "            rank[p] = 0\n",
    "            if p not in front[0]:\n",
    "                front[0].append(p)\n",
    "\n",
    "    i = 0\n",
    "    while(front[i] != []):\n",
    "        Q=[]\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] =n[q] - 1\n",
    "                if( n[q]==0):\n",
    "                    rank[q]=i+1\n",
    "                    if q not in Q:\n",
    "                        Q.append(q)\n",
    "        i = i+1\n",
    "        front.append(Q)\n",
    "\n",
    "    del front[len(front)-1]\n",
    "    return front\n",
    "\n",
    "#Function to calculate crowding distance\n",
    "def crowding_distance(values1, values2, front):\n",
    "    distance = [0 for i in range(0,len(front))]\n",
    "    sorted1 = sort_by_values(front, values1[:])\n",
    "    sorted2 = sort_by_values(front, values2[:])\n",
    "    distance[0] = 4444444444444444\n",
    "    distance[len(front) - 1] = 4444444444444444\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "    return distance\n",
    "\n",
    "#Function to carry out the crossover\n",
    "def crossover(solution1, solution2):\n",
    "    r = random.randint(0, number_of_features_preselected - 1)\n",
    "    tmp = solution1[:r].copy()\n",
    "    solution1[:r], solution2[:r]  = solution2[:r], tmp\n",
    "    return solution1\n",
    "\n",
    "#Function to carry out the mutation operator\n",
    "def mutation(solution1):\n",
    "    r = random.randint(0, number_of_features_preselected - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "#Main program starts here\n",
    "pop_size = 50\n",
    "max_gen = 100\n",
    "\n",
    "#Initialization\n",
    "solution = [list(np.random.randint(2, size = number_of_features_preselected)) for i in range(0,pop_size)]\n",
    "[mutation(s) for s in solution if sum(s) == 0]\n",
    "gen_no = 0\n",
    "while(gen_no < max_gen):\n",
    "    function1_values = [function1(solution[i]) for i in range(0,pop_size)]\n",
    "    function2_values = [function2(solution[i]) for i in range(0,pop_size)]\n",
    "    non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])\n",
    "    print(\"The best front for Generation number \",gen_no, \" is\")\n",
    "    for valuez in non_dominated_sorted_solution[0]:\n",
    "        print(solution[valuez], function1(solution[valuez]), function2(solution[valuez]), end=\" \")\n",
    "        print(\"\\n\")\n",
    "    print(\"\\n\")\n",
    "    crowding_distance_values=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution)):\n",
    "        crowding_distance_values.append(crowding_distance(function1_values[:],function2_values[:],non_dominated_sorted_solution[i][:]))\n",
    "    solution2 = solution[:]\n",
    "    #Generating offsprings\n",
    "    while(len(solution2)!=2*pop_size):\n",
    "        a1 = random.randint(0,pop_size-1)\n",
    "        b1 = random.randint(0,pop_size-1)\n",
    "        c1 = crossover(solution[a1],solution[b1])\n",
    "        #d1 = mutation(c1)\n",
    "        solution2.append(c1)\n",
    "    [mutation(s) for s in solution2 if sum(s) == 0]\n",
    "    function1_values2 = [function1(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    function2_values2 = [function2(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    non_dominated_sorted_solution2 = fast_non_dominated_sort(function1_values2[:],function2_values2[:])\n",
    "    crowding_distance_values2=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        crowding_distance_values2.append(crowding_distance(function1_values2[:],function2_values2[:],non_dominated_sorted_solution2[i][:]))\n",
    "    new_solution= []\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i]) for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "        front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front.reverse()\n",
    "        for value in front:\n",
    "            new_solution.append(value)\n",
    "            if(len(new_solution)==pop_size):\n",
    "                break\n",
    "        if (len(new_solution) == pop_size):\n",
    "            break\n",
    "    solution = [solution2[i] for i in new_solution]\n",
    "    gen_no = gen_no + 1\n",
    "\n",
    "#Lets plot the final front now\n",
    "function1 = [i * -1 for i in function1_values]\n",
    "function2 = [j * 1 for j in function2_values]\n",
    "plt.xlabel('Function 1', fontsize=15)\n",
    "plt.ylabel('Function 2', fontsize=15)\n",
    "plt.scatter(function1, function2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "Author:\n",
    "    GOSHGAR ISMAYILOV\n",
    "    SERHAT İŞCAN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
