{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature (Gene) Selection with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get user inputs (name of dataset and objectives be considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = sys.argv[1]\n",
    "objectives   = sys.argv[2]\n",
    "dataset_name = 'shipp'     # gordon: lung # shipp: lymphoma # singh: prostate # tian: myeloma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('Datasets/' + dataset_name + '_inputs.csv', header = None)\n",
    "labels = pd.read_csv('Datasets/' + dataset_name + '_outputs.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-process dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.fillna(0, inplace = True)\n",
    "samples = np.asarray(samples.values)\n",
    "labels = np.transpose(np.asarray(labels.values.ravel() - 1, dtype=int))\n",
    "samples = preprocessing.MinMaxScaler().fit_transform(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pre-select best 100 features with univariate chi square statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = SelectKBest(chi2, k = 10).fit_transform(samples, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Be ready! Last preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes           = [0, 1]\n",
    "scores            = []\n",
    "loo               = LeaveOneOut()\n",
    "cv                = KFold(n_splits = 10, shuffle=False)\n",
    "number_of_classes = np.max(labels) + 1\n",
    "batch_size        = 1\n",
    "epochs            = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8196428571428571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def SVM(indexes):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = LinearSVC(random_state=0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    average_score = float(np.average(scores))\n",
    "    #print('Score: ', average_score)\n",
    "    #print('Time: ', end_time - start_time)\n",
    "    return average_score\n",
    "    \n",
    "SVM(indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Apply Non-Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8043010752688172\n",
      "Time: 0.33297133445739746\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for train_index, test_index in loo.split(samples):\n",
    "    x_train, x_test = samples[train_index], samples[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    X_train = x_train[:, indexes]\n",
    "    X_test = x_test[:, indexes]\n",
    "    Y_train = y_train[:]\n",
    "    Y_test = y_test[:]\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    Y_train = Y_train[:]\n",
    "    Y_test = Y_test[:]\n",
    "    \n",
    "    classifier = SVC(kernel = 'rbf', random_state=0) # rbf == gaussian\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    score = classifier.score(X_test, Y_test)\n",
    "    scores.append(score)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Score: ' + str(np.average(scores)))\n",
    "print('Time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Apply k-NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.7933579335793358\n",
      "Time: 0.36500000953674316\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for train_index, test_index in loo.split(samples):\n",
    "    x_train, x_test = samples[train_index], samples[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    X_train = x_train[:, indexes]\n",
    "    X_test = x_test[:, indexes]\n",
    "    Y_train = y_train[:]\n",
    "    Y_test = y_test[:]\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    Y_train = Y_train[:]\n",
    "    Y_test = Y_test[:]\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    score = classifier.score(X_test, Y_test)\n",
    "    scores.append(score)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Score: ' + str(np.average(scores)))\n",
    "print('Time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Apply NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "c:\\users\\pc_313_admin\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for train_index, test_index in loo.split(samples):\n",
    "    x_train, x_test = samples[train_index], samples[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    X_train = x_train[:, indexes]\n",
    "    X_test = x_test[:, indexes]\n",
    "    Y_train = y_train[:]\n",
    "    Y_test = y_test[:]\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    Y_train = Y_train[:]\n",
    "    Y_test = Y_test[:]\n",
    "    \n",
    "    classifier = MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu', solver='adam', max_iter=500)\n",
    "    classifier.fit(X_train, Y_train)\n",
    "    score = classifier.score(X_test, Y_test)\n",
    "    scores.append(score)\n",
    "end_time = time.time()\n",
    "\n",
    "print('Score: ' + str(np.average(scores)))\n",
    "print('Time: ' + str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Apply NSGA-II!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best front for Generation number  0  is\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 0] 0.8333585714285715 [1, 0, 1, 0, 0, 0, 1, 0, 1, 1] 0.833363309352518 [0, 0, 0, 0, 0, 0, 1, 0, 0, 1] 0.8333880077590141 \n",
      "\n",
      "The best front for Generation number  1  is\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0] 0.8355769230769231 [1, 0, 0, 0, 0, 0, 1, 0, 0, 1] 0.835587899543379 \n",
      "\n",
      "The best front for Generation number  2  is\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 0.8366285714285714 [0, 0, 0, 0, 0, 0, 1, 0, 1, 0] 0.8366071428571429 [1, 0, 0, 1, 1, 1, 0, 1, 1, 1] 0.83666744475568 [0, 1, 0, 0, 0, 0, 0, 0, 1, 1] 0.8366602736885757 \n",
      "\n",
      "The best front for Generation number  3  is\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 1] 0.8383512856150104 [0, 1, 0, 0, 0, 0, 0, 0, 1, 1] 0.8383432539682539 [1, 0, 0, 1, 0, 1, 0, 0, 1, 0] 0.8383612570635471 \n",
      "\n",
      "The best front for Generation number  4  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0] 0.8398754042229408 [1, 0, 0, 0, 0, 0, 0, 0, 1, 1] 0.8398928333808574 [1, 1, 1, 0, 0, 0, 0, 0, 0, 1] 0.8399375474924011 \n",
      "\n",
      "The best front for Generation number  5  is\n",
      "[0, 1, 0, 0, 1, 0, 1, 1, 1, 0] 0.8400696029210405 [0, 0, 0, 0, 0, 0, 0, 0, 0, 1] 0.840032612661923 \n",
      "\n",
      "The best front for Generation number  6  is\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 1] 0.8395271753446307 [0, 0, 0, 0, 0, 0, 1, 0, 1, 0] 0.8395072832572832 [1, 0, 0, 0, 0, 1, 1, 1, 0, 0] 0.8395301674997807 \n",
      "\n",
      "The best front for Generation number  7  is\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 1, 0] 0.8395784023668639 [0, 0, 0, 1, 0, 0, 0, 0, 0, 1] 0.8395539410323561 [0, 0, 0, 0, 1, 0, 0, 1, 1, 0] 0.8395601148260723 \n",
      "\n",
      "The best front for Generation number  8  is\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 1, 1] 0.8409593757639964 [0, 1, 0, 1, 0, 1, 1, 0, 1, 0] 0.8409879459195309 \n",
      "\n",
      "The best front for Generation number  9  is\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 1, 1] 0.840590318772137 [0, 0, 0, 0, 0, 0, 0, 1, 0, 1] 0.8405581340465701 [0, 0, 0, 1, 0, 1, 1, 0, 1, 0] 0.8405711927038289 [1, 0, 0, 0, 0, 1, 0, 0, 1, 0] 0.8405842369951281 \n",
      "\n",
      "The best front for Generation number  10  is\n",
      "[0, 0, 0, 0, 1, 0, 1, 0, 0, 0] 0.8413280240249373 [1, 0, 0, 0, 0, 1, 0, 1, 0, 0] 0.8413316869300912 [0, 0, 0, 0, 0, 1, 1, 0, 1, 1] 0.8413514847725373 \n",
      "\n",
      "The best front for Generation number  11  is\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1] 0.8404158084449022 \n",
      "\n",
      "The best front for Generation number  12  is\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 1, 0] 0.8413442336495257 [0, 0, 0, 0, 1, 0, 0, 1, 0, 1] 0.8413628100940975 [1, 1, 0, 0, 0, 0, 1, 0, 1, 0] 0.8413938368364802 [1, 0, 0, 1, 0, 1, 0, 0, 1, 1] 0.8414070289132602 \n",
      "\n",
      "The best front for Generation number  13  is\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 1, 1] 0.8412865436450341 [1, 0, 0, 1, 0, 1, 1, 1, 0, 0] 0.8413106175739155 [0, 0, 0, 0, 0, 0, 0, 0, 1, 1] 0.8412966926741697 \n",
      "\n",
      "The best front for Generation number  14  is\n",
      "[1, 0, 0, 0, 0, 1, 0, 1, 1, 1] 0.8418100268276325 [0, 0, 0, 0, 1, 0, 0, 0, 1, 0] 0.8418004625594958 \n",
      "\n",
      "The best front for Generation number  15  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0] 0.8426103037017726 [1, 0, 0, 0, 0, 0, 1, 1, 1, 0] 0.8426381017523289 [0, 1, 0, 1, 1, 1, 0, 0, 1, 1] 0.8426731996353692 \n",
      "\n",
      "The best front for Generation number  16  is\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0] 0.8429608805828317 \n",
      "\n",
      "The best front for Generation number  17  is\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 1, 1] 0.8430244571922033 [0, 0, 0, 1, 1, 1, 0, 0, 0, 0] 0.843027467784697 \n",
      "\n",
      "The best front for Generation number  18  is\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 1, 0] 0.8436681485041452 [0, 1, 0, 1, 1, 0, 1, 0, 0, 0] 0.8436933285293942 \n",
      "\n",
      "The best front for Generation number  19  is\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0] 0.844063231850117 [1, 0, 0, 0, 0, 1, 0, 0, 1, 1] 0.8440729794580675 [1, 1, 0, 1, 0, 1, 0, 0, 1, 0] 0.8440819878319877 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#First function to optimize\n",
    "def function1(x):\n",
    "    value = -sum(x)\n",
    "    return value\n",
    "\n",
    "#Second function to optimize\n",
    "def function2(x):\n",
    "    indexes = [i for i, v in enumerate(x) if v == 1]\n",
    "    if indexes == []: indexes = [0]\n",
    "    value = SVM(indexes)\n",
    "    return value\n",
    "\n",
    "#Function to find index of list\n",
    "def index_of(a,list):\n",
    "    for i in range(0,len(list)):\n",
    "        if list[i] == a:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "#Function to sort by values\n",
    "def sort_by_values(list1, values):\n",
    "    sorted_list = []\n",
    "    while(len(sorted_list)!=len(list1)):\n",
    "        if index_of(min(values),values) in list1:\n",
    "            sorted_list.append(index_of(min(values),values))\n",
    "        values[index_of(min(values),values)] = math.inf\n",
    "    return sorted_list\n",
    "\n",
    "#Function to carry out NSGA-II's fast non dominated sort\n",
    "def fast_non_dominated_sort(values1, values2):\n",
    "    S=[[] for i in range(0,len(values1))]\n",
    "    front = [[]]\n",
    "    n=[0 for i in range(0,len(values1))]\n",
    "    rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "    for p in range(0,len(values1)):\n",
    "        S[p]=[]\n",
    "        n[p]=0\n",
    "        for q in range(0, len(values1)):\n",
    "            if (values1[p] > values1[q] and values2[p] > values2[q]) or (values1[p] >= values1[q] and values2[p] > values2[q]) or (values1[p] > values1[q] and values2[p] >= values2[q]):\n",
    "                if q not in S[p]:\n",
    "                    S[p].append(q)\n",
    "            elif (values1[q] > values1[p] and values2[q] > values2[p]) or (values1[q] >= values1[p] and values2[q] > values2[p]) or (values1[q] > values1[p] and values2[q] >= values2[p]):\n",
    "                n[p] = n[p] + 1\n",
    "        if n[p]==0:\n",
    "            rank[p] = 0\n",
    "            if p not in front[0]:\n",
    "                front[0].append(p)\n",
    "\n",
    "    i = 0\n",
    "    while(front[i] != []):\n",
    "        Q=[]\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] =n[q] - 1\n",
    "                if( n[q]==0):\n",
    "                    rank[q]=i+1\n",
    "                    if q not in Q:\n",
    "                        Q.append(q)\n",
    "        i = i+1\n",
    "        front.append(Q)\n",
    "\n",
    "    del front[len(front)-1]\n",
    "    return front\n",
    "\n",
    "#Function to calculate crowding distance\n",
    "def crowding_distance(values1, values2, front):\n",
    "    distance = [0 for i in range(0,len(front))]\n",
    "    sorted1 = sort_by_values(front, values1[:])\n",
    "    sorted2 = sort_by_values(front, values2[:])\n",
    "    distance[0] = 4444444444444444\n",
    "    distance[len(front) - 1] = 4444444444444444\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "    return distance\n",
    "\n",
    "#Function to carry out the crossover\n",
    "def crossover(solution1, solution2):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    tmp = solution1[:r].copy()\n",
    "    solution1[:r], solution2[:r]  = solution2[:r], tmp\n",
    "    return solution1\n",
    "\n",
    "#Function to carry out the mutation operator\n",
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "#Main program starts here\n",
    "pop_size = 20\n",
    "max_gen = 20\n",
    "number_of_genes = 10\n",
    "\n",
    "#Initialization\n",
    "solution = [list(np.random.randint(2, size = number_of_genes)) for i in range(0,pop_size)]\n",
    "[mutation(s) for s in solution if sum(s) == 0]\n",
    "gen_no = 0\n",
    "while(gen_no<max_gen):\n",
    "    function1_values = [function1(solution[i]) for i in range(0,pop_size)]\n",
    "    function2_values = [function2(solution[i]) for i in range(0,pop_size)]\n",
    "    non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])\n",
    "    print(\"The best front for Generation number \",gen_no, \" is\")\n",
    "    for valuez in non_dominated_sorted_solution[0]:\n",
    "        print(solution[valuez], function2(solution[valuez]), end=\" \")\n",
    "    print(\"\\n\")\n",
    "    crowding_distance_values=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution)):\n",
    "        crowding_distance_values.append(crowding_distance(function1_values[:],function2_values[:],non_dominated_sorted_solution[i][:]))\n",
    "    solution2 = solution[:]\n",
    "    #Generating offsprings\n",
    "    while(len(solution2)!=2*pop_size):\n",
    "        a1 = random.randint(0,pop_size-1)\n",
    "        b1 = random.randint(0,pop_size-1)\n",
    "        c1 = crossover(solution[a1],solution[b1])\n",
    "        #d1 = mutation(c1)\n",
    "        solution2.append(c1)\n",
    "    [mutation(s) for s in solution2 if sum(s) == 0]\n",
    "    function1_values2 = [function1(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    function2_values2 = [function2(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    non_dominated_sorted_solution2 = fast_non_dominated_sort(function1_values2[:],function2_values2[:])\n",
    "    crowding_distance_values2=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        crowding_distance_values2.append(crowding_distance(function1_values2[:],function2_values2[:],non_dominated_sorted_solution2[i][:]))\n",
    "    new_solution= []\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i]) for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "        front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front.reverse()\n",
    "        for value in front:\n",
    "            new_solution.append(value)\n",
    "            if(len(new_solution)==pop_size):\n",
    "                break\n",
    "        if (len(new_solution) == pop_size):\n",
    "            break\n",
    "    solution = [solution2[i] for i in new_solution]\n",
    "    gen_no = gen_no + 1\n",
    "\n",
    "#Lets plot the final front now\n",
    "function1 = [i * -1 for i in function1_values]\n",
    "function2 = [j * -1 for j in function2_values]\n",
    "plt.xlabel('Function 1', fontsize=15)\n",
    "plt.ylabel('Function 2', fontsize=15)\n",
    "plt.scatter(function1, function2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 0, 0, 1, 0, 1, 0], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1], [1, 0, 1, 0, 0, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 0, 0, 1, 0, 1, 1, 0, 0, 1], [0, 0, 0, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 1, 0, 1, 0, 1]]\n",
      "\n",
      "[[0, 1, 0, 0, 1, 1, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 1, 0, 0], [1, 1, 1, 0, 1, 0, 1, 0, 1, 0], [1, 1, 1, 0, 0, 0, 1, 1, 0, 1], [1, 1, 1, 0, 0, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 0, 0, 0], [0, 1, 1, 1, 0, 1, 0, 1, 1, 1], [0, 0, 0, 1, 0, 1, 1, 0, 0, 1], [0, 0, 0, 1, 0, 0, 1, 0, 0, 1], [0, 0, 1, 0, 1, 0, 0, 1, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "solution = [list(np.random.randint(2, size = 10)) for i in range(0,10)]\n",
    "print(solution)\n",
    "print()\n",
    "[mutation(s) for s in solution if sum(s) == 5]\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "Author:\n",
    "    GOSHGAR ISMAYILOV\n",
    "    SERHAT İŞCAN\n",
    "\n",
    "Project Description:\n",
    "\n",
    "    In this project, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "1. Your are not allowed to use Numpy.\n",
    "2. You are not allowed to use any libraries to find the Needleman Wunsch and Smith Waterman scores.\n",
    "3. You can only use standard libraries apart from the given codes.\n",
    "4. Please submit your assignment using Moodle. Upload a single zip file named as YourNameSurname.zip. Your zip file should include your report, your source code, and the corresponding read.me file. You can use any programming language of your choice. But, your read.me file should clearly explain how to run your program.\n",
    "5. For any question e-mail me from selen.parlar@boun.edu.tr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
