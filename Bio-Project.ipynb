{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bioinformatics Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature (Gene) Selection for Microarray Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get user inputs (name of dataset and objectives be considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = sys.argv[1]\n",
    "objectives   = sys.argv[2]\n",
    "dataset_name = 'shipp'     # gordon: lung # shipp: lymphoma # singh: prostate # tian: myeloma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = pd.read_csv('Datasets/' + dataset_name + '_inputs.csv', header = None)\n",
    "labels = pd.read_csv('Datasets/' + dataset_name + '_outputs.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pre-process dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.fillna(0, inplace = True)\n",
    "samples = np.asarray(samples.values)\n",
    "labels = np.transpose(np.asarray(labels.values.ravel() - 1, dtype=int))\n",
    "samples = preprocessing.MinMaxScaler().fit_transform(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Pre-select best 100 features with univariate chi square statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = SelectKBest(chi2, k = 100).fit_transform(samples, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Be ready! Last preparations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes           = [0, 1]\n",
    "scores            = []\n",
    "loo               = LeaveOneOut()\n",
    "cv                = KFold(n_splits = 10, shuffle=False)\n",
    "number_of_classes = np.max(labels) + 1\n",
    "batch_size        = 1\n",
    "epochs            = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Apply Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.038027048110961914\n",
      "Score: 0.7892857142857143\n"
     ]
    }
   ],
   "source": [
    "def linearSVM(indexes,print_time=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in cv.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = LinearSVC(random_state=0)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = linearSVM(indexes)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Apply Non-Linear SVM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.2862246036529541\n",
      "Score: 0.849343185550082\n"
     ]
    }
   ],
   "source": [
    "def nonLinearSVM(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = SVC(kernel = 'rbf', random_state=0) # rbf == gaussian\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = nonLinearSVM(indexes)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Apply k-NN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.32625865936279297\n",
      "Score: 0.8286149825783972\n"
     ]
    }
   ],
   "source": [
    "def kNN(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = kNN(indexes)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Apply MLP classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 41.69305944442749\n",
      "Score: 0.8294309425014819\n"
     ]
    }
   ],
   "source": [
    "def MLP(indexes, print_time=True):\n",
    "\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = MLPClassifier(hidden_layer_sizes=(10, 10), activation='relu', solver='adam', max_iter=3000)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = MLP(indexes)\n",
    "print(\"Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply decision tree classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.07805418968200684\n",
      "Score: 0.817273135669362\n"
     ]
    }
   ],
   "source": [
    "def DTree(indexes, print_time=True):\n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        decision_tree = DecisionTreeClassifier()\n",
    "        decision_tree = decision_tree.fit(X_train, Y_train)\n",
    "        score = decision_tree.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = DTree(indexes)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply random forest classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 30.12931728363037\n",
      "Score: 0.8149186256781192\n"
     ]
    }
   ],
   "source": [
    "def RForest(indexes, print_time=True):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for train_index, test_index in loo.split(samples):\n",
    "        x_train, x_test = samples[train_index], samples[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "        X_train = x_train[:, indexes]\n",
    "        X_test = x_test[:, indexes]\n",
    "        Y_train = y_train[:]\n",
    "        Y_test = y_test[:]\n",
    "\n",
    "        X_train = X_train.astype('float32')\n",
    "        X_test = X_test.astype('float32')\n",
    "        Y_train = Y_train[:]\n",
    "        Y_test = Y_test[:]\n",
    "\n",
    "        classifier = RandomForestClassifier(n_estimators=100)\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        score = classifier.score(X_test, Y_test)\n",
    "        scores.append(score)\n",
    "    end_time = time.time()\n",
    "\n",
    "    average_score = np.average(scores)\n",
    "    completion_time = end_time - start_time\n",
    "    if print_time:\n",
    "        print(\"Time: \" + str(completion_time))\n",
    "    return average_score\n",
    "    \n",
    "score = RForest(indexes)\n",
    "print(\"Score: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Apply NSGA-II!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best front for Generation number  0  is\n",
      "[0, 1, 0, 1, 0, 1, 1, 0, 1, 1] 0.7930637544273909 [1, 1, 0, 0, 0, 0, 0, 1, 0, 1] 0.792595818815331 [0, 0, 0, 0, 1, 0, 0, 0, 1, 1] 0.7912571428571428 \n",
      "\n",
      "The best front for Generation number  1  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1] 0.7743782533256218 \n",
      "\n",
      "The best front for Generation number  2  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 1] 0.7642663569492838 \n",
      "\n",
      "The best front for Generation number  3  is\n",
      "[1, 0, 0, 1, 0, 1, 1, 0, 1, 1] 0.7600378236834449 [0, 1, 0, 0, 1, 1, 0, 0, 1, 1] 0.7600115908432338 [1, 0, 0, 1, 0, 1, 0, 0, 0, 0] 0.75997113997114 \n",
      "\n",
      "The best front for Generation number  4  is\n",
      "[0, 0, 1, 1, 0, 0, 1, 1, 1, 1] 0.759591340588099 [0, 0, 1, 1, 0, 0, 0, 1, 0, 0] 0.7595141933994922 [1, 1, 0, 0, 0, 0, 0, 0, 1, 1] 0.7595410628019323 \n",
      "\n",
      "The best front for Generation number  5  is\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.7537781195923862 [1, 0, 1, 1, 0, 0, 0, 1, 1, 1] 0.7538446788111217 \n",
      "\n",
      "The best front for Generation number  6  is\n",
      "[1, 1, 0, 0, 0, 0, 0, 1, 0, 0] 0.7520349316197067 \n",
      "\n",
      "The best front for Generation number  7  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.7495522172468582 \n",
      "\n",
      "The best front for Generation number  8  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 0.7467146714671468 [1, 1, 1, 0, 0, 1, 1, 0, 0, 1] 0.7467494544987805 \n",
      "\n",
      "The best front for Generation number  9  is\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 1] 0.7454366685945631 [1, 0, 0, 1, 1, 1, 0, 1, 1, 1] 0.7454960157062016 \n",
      "\n",
      "The best front for Generation number  10  is\n",
      "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0] 0.7437033533060023 [1, 0, 0, 1, 0, 0, 0, 1, 0, 1] 0.7437126062768973 \n",
      "\n",
      "The best front for Generation number  11  is\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 1, 0] 0.7449089683074849 [1, 0, 0, 1, 0, 0, 1, 0, 1, 1] 0.7449543049543049 \n",
      "\n",
      "The best front for Generation number  12  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0] 0.7430704951551249 [1, 0, 0, 1, 0, 0, 1, 0, 1, 1] 0.743114623102193 \n",
      "\n",
      "The best front for Generation number  13  is\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 1, 1] 0.7418894940991995 [0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 0.741801994889127 \n",
      "\n",
      "The best front for Generation number  14  is\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1] 0.7411397766653831 [1, 0, 1, 0, 0, 1, 0, 1, 1, 0] 0.7411666282021694 [0, 0, 1, 1, 0, 0, 0, 1, 0, 0] 0.7411607623146085 \n",
      "\n",
      "The best front for Generation number  15  is\n",
      "[1, 0, 1, 0, 0, 0, 0, 1, 0, 0] 0.7421432177111127 [1, 0, 0, 1, 0, 0, 0, 0, 1, 1] 0.7421817592392479 \n",
      "\n",
      "The best front for Generation number  16  is\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 1] 0.7436206311503224 [1, 0, 0, 1, 0, 0, 0, 1, 1, 0] 0.7436673672791375 \n",
      "\n",
      "The best front for Generation number  17  is\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 1] 0.7432016278920721 [0, 0, 0, 1, 0, 0, 0, 0, 1, 0] 0.7431356854709612 \n",
      "\n",
      "The best front for Generation number  18  is\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 0, 0] 0.7431758848885921 [1, 0, 1, 1, 0, 0, 0, 0, 0, 1] 0.7432059447983015 \n",
      "\n",
      "The best front for Generation number  19  is\n",
      "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0] 0.7444071169040891 [1, 0, 0, 0, 0, 0, 0, 1, 1, 0] 0.7444462052671007 [1, 0, 1, 1, 0, 0, 0, 0, 0, 1] 0.7444737145160361 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#First function to optimize\n",
    "def function1(x):\n",
    "    value = -sum(x)\n",
    "    return value\n",
    "\n",
    "#Second function to optimize\n",
    "def function2(x):\n",
    "    indexes = [i for i, v in enumerate(x) if v == 1]\n",
    "    if indexes == []: indexes = [0]\n",
    "    value = linearSVM(indexes, False)\n",
    "    return value\n",
    "\n",
    "#Function to find index of list\n",
    "def index_of(a,list):\n",
    "    for i in range(0,len(list)):\n",
    "        if list[i] == a:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "#Function to sort by values\n",
    "def sort_by_values(list1, values):\n",
    "    sorted_list = []\n",
    "    while(len(sorted_list)!=len(list1)):\n",
    "        if index_of(min(values),values) in list1:\n",
    "            sorted_list.append(index_of(min(values),values))\n",
    "        values[index_of(min(values),values)] = math.inf\n",
    "    return sorted_list\n",
    "\n",
    "#Function to carry out NSGA-II's fast non dominated sort\n",
    "def fast_non_dominated_sort(values1, values2):\n",
    "    S=[[] for i in range(0,len(values1))]\n",
    "    front = [[]]\n",
    "    n=[0 for i in range(0,len(values1))]\n",
    "    rank = [0 for i in range(0, len(values1))]\n",
    "\n",
    "    for p in range(0,len(values1)):\n",
    "        S[p]=[]\n",
    "        n[p]=0\n",
    "        for q in range(0, len(values1)):\n",
    "            if (values1[p] > values1[q] and values2[p] > values2[q]) or (values1[p] >= values1[q] and values2[p] > values2[q]) or (values1[p] > values1[q] and values2[p] >= values2[q]):\n",
    "                if q not in S[p]:\n",
    "                    S[p].append(q)\n",
    "            elif (values1[q] > values1[p] and values2[q] > values2[p]) or (values1[q] >= values1[p] and values2[q] > values2[p]) or (values1[q] > values1[p] and values2[q] >= values2[p]):\n",
    "                n[p] = n[p] + 1\n",
    "        if n[p]==0:\n",
    "            rank[p] = 0\n",
    "            if p not in front[0]:\n",
    "                front[0].append(p)\n",
    "\n",
    "    i = 0\n",
    "    while(front[i] != []):\n",
    "        Q=[]\n",
    "        for p in front[i]:\n",
    "            for q in S[p]:\n",
    "                n[q] =n[q] - 1\n",
    "                if( n[q]==0):\n",
    "                    rank[q]=i+1\n",
    "                    if q not in Q:\n",
    "                        Q.append(q)\n",
    "        i = i+1\n",
    "        front.append(Q)\n",
    "\n",
    "    del front[len(front)-1]\n",
    "    return front\n",
    "\n",
    "#Function to calculate crowding distance\n",
    "def crowding_distance(values1, values2, front):\n",
    "    distance = [0 for i in range(0,len(front))]\n",
    "    sorted1 = sort_by_values(front, values1[:])\n",
    "    sorted2 = sort_by_values(front, values2[:])\n",
    "    distance[0] = 4444444444444444\n",
    "    distance[len(front) - 1] = 4444444444444444\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted1[k+1]] - values2[sorted1[k-1]])/(max(values1)-min(values1))\n",
    "    for k in range(1,len(front)-1):\n",
    "        distance[k] = distance[k]+ (values1[sorted2[k+1]] - values2[sorted2[k-1]])/(max(values2)-min(values2))\n",
    "    return distance\n",
    "\n",
    "#Function to carry out the crossover\n",
    "def crossover(solution1, solution2):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    tmp = solution1[:r].copy()\n",
    "    solution1[:r], solution2[:r]  = solution2[:r], tmp\n",
    "    return solution1\n",
    "\n",
    "#Function to carry out the mutation operator\n",
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "#Main program starts here\n",
    "pop_size = 20\n",
    "max_gen = 20\n",
    "number_of_genes = 10\n",
    "\n",
    "#Initialization\n",
    "solution = [list(np.random.randint(2, size = number_of_genes)) for i in range(0,pop_size)]\n",
    "[mutation(s) for s in solution if sum(s) == 0]\n",
    "gen_no = 0\n",
    "while(gen_no<max_gen):\n",
    "    function1_values = [function1(solution[i]) for i in range(0,pop_size)]\n",
    "    function2_values = [function2(solution[i]) for i in range(0,pop_size)]\n",
    "    non_dominated_sorted_solution = fast_non_dominated_sort(function1_values[:],function2_values[:])\n",
    "    print(\"The best front for Generation number \",gen_no, \" is\")\n",
    "    for valuez in non_dominated_sorted_solution[0]:\n",
    "        print(solution[valuez], function2(solution[valuez]), end=\" \")\n",
    "    print(\"\\n\")\n",
    "    crowding_distance_values=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution)):\n",
    "        crowding_distance_values.append(crowding_distance(function1_values[:],function2_values[:],non_dominated_sorted_solution[i][:]))\n",
    "    solution2 = solution[:]\n",
    "    #Generating offsprings\n",
    "    while(len(solution2)!=2*pop_size):\n",
    "        a1 = random.randint(0,pop_size-1)\n",
    "        b1 = random.randint(0,pop_size-1)\n",
    "        c1 = crossover(solution[a1],solution[b1])\n",
    "        #d1 = mutation(c1)\n",
    "        solution2.append(c1)\n",
    "    [mutation(s) for s in solution2 if sum(s) == 0]\n",
    "    function1_values2 = [function1(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    function2_values2 = [function2(solution2[i]) for i in range(0,2*pop_size)]\n",
    "    non_dominated_sorted_solution2 = fast_non_dominated_sort(function1_values2[:],function2_values2[:])\n",
    "    crowding_distance_values2=[]\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        crowding_distance_values2.append(crowding_distance(function1_values2[:],function2_values2[:],non_dominated_sorted_solution2[i][:]))\n",
    "    new_solution= []\n",
    "    for i in range(0,len(non_dominated_sorted_solution2)):\n",
    "        non_dominated_sorted_solution2_1 = [index_of(non_dominated_sorted_solution2[i][j],non_dominated_sorted_solution2[i]) for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front22 = sort_by_values(non_dominated_sorted_solution2_1[:], crowding_distance_values2[i][:])\n",
    "        front = [non_dominated_sorted_solution2[i][front22[j]] for j in range(0,len(non_dominated_sorted_solution2[i]))]\n",
    "        front.reverse()\n",
    "        for value in front:\n",
    "            new_solution.append(value)\n",
    "            if(len(new_solution)==pop_size):\n",
    "                break\n",
    "        if (len(new_solution) == pop_size):\n",
    "            break\n",
    "    solution = [solution2[i] for i in new_solution]\n",
    "    gen_no = gen_no + 1\n",
    "\n",
    "#Lets plot the final front now\n",
    "function1 = [i * -1 for i in function1_values]\n",
    "function2 = [j * -1 for j in function2_values]\n",
    "plt.xlabel('Function 1', fontsize=15)\n",
    "plt.ylabel('Function 2', fontsize=15)\n",
    "plt.scatter(function1, function2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 0, 0, 1, 0, 0, 1, 0, 1], [0, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 0, 0, 1, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 1, 1, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 0, 0, 1, 1, 1, 1, 1], [1, 1, 0, 0, 0, 1, 1, 1, 1, 1], [1, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 1, 0, 1, 0, 1, 0, 1, 1, 0], [1, 0, 0, 0, 0, 0, 1, 1, 1, 1]]\n",
      "\n",
      "[[0, 1, 0, 0, 1, 0, 0, 1, 0, 1], [0, 0, 1, 1, 0, 0, 1, 0, 0, 1], [1, 1, 0, 0, 1, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0, 0, 1, 0, 1], [1, 1, 1, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 0, 0, 1, 1, 1, 1, 1], [1, 1, 0, 0, 0, 1, 1, 1, 1, 1], [1, 0, 0, 1, 1, 0, 1, 1, 1, 0], [0, 1, 0, 1, 0, 1, 0, 1, 0, 0], [1, 0, 1, 0, 0, 0, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "def mutation(solution1):\n",
    "    number_of_genes = 10\n",
    "    r = random.randint(0, number_of_genes - 1)\n",
    "    solution1[r] = 1 - solution1[r]\n",
    "    return solution1\n",
    "\n",
    "solution = [list(np.random.randint(2, size = 10)) for i in range(0,10)]\n",
    "print(solution)\n",
    "print()\n",
    "[mutation(s) for s in solution if sum(s) == 5]\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments\n",
    "\n",
    "Author:\n",
    "    GOSHGAR ISMAYILOV\n",
    "    SERHAT İŞCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
